{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '../data/pcs-scraping'\n",
    "RESULTS_PATH = '../data/pcs-scraping/results/rider'\n",
    "RANKINGS_PATH = '../data/pcs-scraping/pcs-rankings/rider'\n",
    "TEAMS_PATH = '../data/pcs-scraping/teams/rider'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rider_names(n_pages):\n",
    "    \n",
    "    rider_names = []\n",
    "\n",
    "    offsets = np.arange(0, 3001, 100)\n",
    "\n",
    "    for offset in offsets[:n_pages]:\n",
    "\n",
    "        url = f'https://www.procyclingstats.com/rankings.php?date=2022-01-12&nation=&age=&zage=&page=smallerorequal&team=&offset={offset}&continent=&teamlevel=&filter=Filter&p=me&s=uci-individual'\n",
    "        res = requests.get(url)\n",
    "\n",
    "        tables = pd.read_html(res.content)\n",
    "        rider_names.append(tables[0])\n",
    "\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    return rider_names\n",
    "\n",
    "def normalize_rider_name(rider_name):\n",
    "    \n",
    "    surname = rider_name.split(\" \")[-1].lower()\n",
    "    name = \"-\".join(rider_name.split(\" \")[:-1]).lower()\n",
    "    full_name = surname + '-' + name\n",
    "    \n",
    "    return full_name\n",
    "\n",
    "def clean_pcs_table_results(df_table):\n",
    "    \n",
    "    df_table.drop('Unnamed: 3', axis=1, inplace=True)\n",
    "    df_table.drop('Unnamed: 8', axis=1, inplace=True)\n",
    "    df_table.rename(columns={'Unnamed: 2': 'GC'}, inplace=True)\n",
    "    \n",
    "    return df_table\n",
    "\n",
    "def clean_pcs_table_ranking(df_table):\n",
    "    \n",
    "    df_table.rename(columns={'Unnamed: 0': 'year'}, inplace=True)\n",
    "\n",
    "    return df_table\n",
    "\n",
    "def get_rider_stats(rider_name, years):\n",
    "\n",
    "    pcs_ranking = []\n",
    "    results = []\n",
    "\n",
    "    for year in years:\n",
    "\n",
    "        try:\n",
    "            url = f'https://www.procyclingstats.com/rider/{rider_name}/{year}'\n",
    "            res = requests.get(url)\n",
    "\n",
    "            tables = pd.read_html(res.content)\n",
    "            pcs_ranking.append(clean_pcs_table_ranking(tables[1]))\n",
    "            results.append(clean_pcs_table_results(tables[0]))\n",
    "\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    df_results = [(year, x) for year, x in zip(years, results) if not x.empty]\n",
    "    \n",
    "    return df_results, pcs_ranking[0]\n",
    "\n",
    "def init_dirs():\n",
    "\n",
    "    if not os.path.isdir(BASE_PATH):\n",
    "        os.makedirs(BASE_PATH)\n",
    "        \n",
    "    if not os.path.isdir(RESULTS_PATH):\n",
    "        os.makedirs(RESULTS_PATH)\n",
    "        \n",
    "    if not os.path.isdir(RANKINGS_PATH):\n",
    "        os.makedirs(RANKINGS_PATH)\n",
    "        \n",
    "    if not os.path.isdir(TEAMS_PATH):\n",
    "        os.makedirs(TEAMS_PATH)\n",
    "\n",
    "def save_data(rider_name, results, pcs_ranking):\n",
    "        \n",
    "    # check if rider already has results data\n",
    "    if not os.path.isdir(os.path.join(RESULTS_PATH, rider_name)):\n",
    "        os.mkdir(os.path.join(RESULTS_PATH, rider_name))\n",
    "    \n",
    "    # check if rider already has pcs-ranking data\n",
    "    if not os.path.isdir(os.path.join(RANKINGS_PATH, rider_name)):\n",
    "        os.mkdir(os.path.join(RANKINGS_PATH, rider_name))\n",
    "        \n",
    "    # save season results\n",
    "    #[x[1].to_csv(f'../data/pcs-scraping/results/rider/{rider_name}/{x[0]}.csv', index=False) for x in results]\n",
    "    [x[1].to_csv(os.path.join(RESULTS_PATH, rider_name , f'{x[0]}.csv'), index=False) for x in results]\n",
    "    \n",
    "    # save pcs_ranking\n",
    "    #pcs_ranking.to_csv(f'../data/pcs-scraping/pcs-ranking/rider/{rider_name}/pcs_ranking.csv', index=False)\n",
    "    pcs_ranking.to_csv(os.path.join(RANKINGS_PATH, rider_name, 'pcs_ranking.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Rider Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rider_names = get_rider_names(n_pages=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "riders = []\n",
    "[riders.extend(x['Rider']) for x in rider_names]\n",
    "\n",
    "rider_names = [normalize_rider_name(x) for x in riders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_PATH, 'rider_names.csv'), 'w') as f:\n",
    "    wr = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(rider_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Race Results and Rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NEED TO SCRAP ALL POSSIBLE YEARS (BEFORE 2011) !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RIDER NAMES NOT CORRECT FOR FAILURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:43<00:00, 10.40s/it]\n"
     ]
    }
   ],
   "source": [
    "years = np.arange(2011, 2022)\n",
    "\n",
    "for rider_name in tqdm.tqdm(rider_names[:10]):\n",
    "\n",
    "    try:\n",
    "        results, pcs_ranking = get_rider_stats(rider_name, years)\n",
    "        save_data(rider_name, results, pcs_ranking)\n",
    "    except:\n",
    "        print(rider_name)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rider_teams(rider_name):\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    url = f'https://www.procyclingstats.com/rider/{rider_name}'\n",
    "    res = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(res.content)\n",
    "    \n",
    "    possible_classes = ['list rdr-teams moblist moblist', 'list rdr-teams moblist', 'list rdr-teams moblist moblist ']\n",
    "    ul = list(filter(None, [soup.find('ul', {'class': class_}) for class_ in possible_classes]))\n",
    "    \n",
    "    if ul:\n",
    "        \n",
    "        season = [x.find('div', {'class': 'season'}).text for x in ul[0].find_all('li')]\n",
    "        team = [x.find('div', {'class': 'name'}).text for x in ul[0].find_all('li')]\n",
    "        teams = pd.DataFrame({'season': season, 'team': team})\n",
    "        \n",
    "        return teams\n",
    "\n",
    "    else:\n",
    "        \n",
    "        print(rider_name, 'No Teams scraped')\n",
    "\n",
    "def save_data(rider_name, teams):\n",
    "        \n",
    "    # check if rider already has teams data\n",
    "    if not os.path.isdir(os.path.join(TEAMS_PATH, rider_name)):\n",
    "        os.mkdir(os.path.join(TEAMS_PATH, rider_name))\n",
    "        \n",
    "    # save teams data\n",
    "    teams.to_csv(os.path.join(TEAMS_PATH, rider_name, 'teams.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rider_names = list(pd.read_csv(os.path.join(BASE_PATH, 'rider_names.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "for rider_name in tqdm.tqdm(rider_names[:10]):\n",
    "    \n",
    "    try:\n",
    "        teams = get_rider_teams(rider_name)\n",
    "        save_data(rider_name, teams)\n",
    "    except:\n",
    "        print(rider_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RIDER NAMES NOT CORRECT ON URL FOR FAILURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
