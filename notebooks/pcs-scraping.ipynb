{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '../data/pcs-scraping'\n",
    "RESULTS_PATH = '../data/pcs-scraping/results/rider'\n",
    "RANKINGS_PATH = '../data/pcs-scraping/pcs-rankings/rider'\n",
    "TEAMS_PATH = '../data/pcs-scraping/teams/rider'\n",
    "CALENDARS_PATH = '../data/pcs-scraping/calendars'\n",
    "STARTLISTS_PATH = '../data/pcs-scraping/startlists'\n",
    "RACERESULTS_PATH = '../data/pcs-scraping/race_results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rider_names(n_pages):\n",
    "    \n",
    "    rider_names = []\n",
    "\n",
    "    offsets = np.arange(0, 3001, 100)\n",
    "\n",
    "    for offset in offsets[:n_pages]:\n",
    "\n",
    "        url = f'https://www.procyclingstats.com/rankings.php?date=2022-01-12&nation=&age=&zage=&page=smallerorequal&team=&offset={offset}&continent=&teamlevel=&filter=Filter&p=me&s=uci-individual'\n",
    "        res = requests.get(url)\n",
    "\n",
    "        tables = pd.read_html(res.content)\n",
    "        rider_names.append(tables[0])\n",
    "\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    return rider_names\n",
    "\n",
    "def normalize_rider_name(rider_name):\n",
    "    \n",
    "    surname = rider_name.split(\" \")[-1].lower()\n",
    "    name = \"-\".join(rider_name.split(\" \")[:-1]).lower()\n",
    "    full_name = surname + '-' + name\n",
    "    \n",
    "    return full_name\n",
    "\n",
    "def clean_pcs_table_results(df_table):\n",
    "    \n",
    "    df_table.drop('Unnamed: 3', axis=1, inplace=True)\n",
    "    df_table.drop('Unnamed: 8', axis=1, inplace=True)\n",
    "    df_table.rename(columns={'Unnamed: 2': 'GC'}, inplace=True)\n",
    "    \n",
    "    return df_table\n",
    "\n",
    "def clean_pcs_table_ranking(df_table):\n",
    "    \n",
    "    df_table.rename(columns={'Unnamed: 0': 'year'}, inplace=True)\n",
    "\n",
    "    return df_table\n",
    "\n",
    "def get_rider_stats(rider_name, years):\n",
    "\n",
    "    pcs_ranking = []\n",
    "    results = []\n",
    "\n",
    "    for year in years:\n",
    "\n",
    "        try:\n",
    "            url = f'https://www.procyclingstats.com/rider/{rider_name}/{year}'\n",
    "            res = requests.get(url)\n",
    "\n",
    "            tables = pd.read_html(res.content)\n",
    "            pcs_ranking.append(clean_pcs_table_ranking(tables[1]))\n",
    "            results.append(clean_pcs_table_results(tables[0]))\n",
    "\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    df_results = [(year, x) for year, x in zip(years, results) if not x.empty]\n",
    "    \n",
    "    return df_results, pcs_ranking[0]\n",
    "\n",
    "def init_dirs():\n",
    "\n",
    "    if not os.path.isdir(BASE_PATH):\n",
    "        os.makedirs(BASE_PATH)\n",
    "        \n",
    "    if not os.path.isdir(RESULTS_PATH):\n",
    "        os.makedirs(RESULTS_PATH)\n",
    "        \n",
    "    if not os.path.isdir(RANKINGS_PATH):\n",
    "        os.makedirs(RANKINGS_PATH)\n",
    "        \n",
    "    if not os.path.isdir(TEAMS_PATH):\n",
    "        os.makedirs(TEAMS_PATH)\n",
    "\n",
    "def save_data(rider_name, results, pcs_ranking):\n",
    "        \n",
    "    # check if rider already has results data\n",
    "    if not os.path.isdir(os.path.join(RESULTS_PATH, rider_name)):\n",
    "        os.mkdir(os.path.join(RESULTS_PATH, rider_name))\n",
    "    \n",
    "    # check if rider already has pcs-ranking data\n",
    "    if not os.path.isdir(os.path.join(RANKINGS_PATH, rider_name)):\n",
    "        os.mkdir(os.path.join(RANKINGS_PATH, rider_name))\n",
    "        \n",
    "    # save season results\n",
    "    #[x[1].to_csv(f'../data/pcs-scraping/results/rider/{rider_name}/{x[0]}.csv', index=False) for x in results]\n",
    "    [x[1].to_csv(os.path.join(RESULTS_PATH, rider_name , f'{x[0]}.csv'), index=False) for x in results]\n",
    "    \n",
    "    # save pcs_ranking\n",
    "    #pcs_ranking.to_csv(f'../data/pcs-scraping/pcs-ranking/rider/{rider_name}/pcs_ranking.csv', index=False)\n",
    "    pcs_ranking.to_csv(os.path.join(RANKINGS_PATH, rider_name, 'pcs_ranking.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Rider Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rider_names = get_rider_names(n_pages=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riders = []\n",
    "[riders.extend(x['Rider']) for x in rider_names]\n",
    "\n",
    "rider_names = [normalize_rider_name(x) for x in riders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_PATH, 'rider_names.csv'), 'w') as f:\n",
    "    wr = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(rider_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Race Results and Rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NEED TO SCRAP ALL POSSIBLE YEARS (BEFORE 2011) !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RIDER NAMES NOT CORRECT FOR FAILURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 7/90 [01:15<14:56, 10.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 8/90 [01:18<11:32,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "jonas-vingegaard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 16/90 [02:34<11:34,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 17/90 [02:37<08:55,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "frølich-honoré-mikkel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 28/90 [04:29<10:08,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 29/90 [04:33<08:01,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "alexey-lutsenko\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 30/90 [04:35<06:14,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "ben-o'connor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 49/90 [07:55<06:49,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 50/90 [07:57<05:10,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "michael-valgren\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 64/90 [10:29<05:05, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 65/90 [10:32<03:48,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "No tables found\n",
      "biniam-girmay-hailu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 80/90 [13:02<01:45, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 81/90 [13:05<01:14,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "No tables found\n",
      "ángel-lópez-miguel\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 82/90 [13:07<00:52,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "esteban-chaves\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 83/90 [13:10<00:37,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "No tables found\n",
      "michał-kwiatkowski\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 87/90 [13:49<00:26,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 88/90 [13:51<00:13,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "jesús-herrada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 89/90 [14:01<00:07,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n",
      "No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [14:03<00:00,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tables found\n",
      "christian-eiking-odd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "years = np.arange(2011, 2022)\n",
    "\n",
    "for rider_name in tqdm.tqdm(rider_names[10:100]):\n",
    "\n",
    "    try:\n",
    "        results, pcs_ranking = get_rider_stats(rider_name, years)\n",
    "        save_data(rider_name, results, pcs_ranking)\n",
    "    except:\n",
    "        print(rider_name)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rider_teams(rider_name):\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    url = f'https://www.procyclingstats.com/rider/{rider_name}'\n",
    "    res = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(res.content)\n",
    "    \n",
    "    possible_classes = ['list rdr-teams moblist moblist', 'list rdr-teams moblist', 'list rdr-teams moblist moblist ']\n",
    "    ul = list(filter(None, [soup.find('ul', {'class': class_}) for class_ in possible_classes]))\n",
    "    \n",
    "    if ul:\n",
    "        \n",
    "        season = [x.find('div', {'class': 'season'}).text for x in ul[0].find_all('li')]\n",
    "        team = [x.find('div', {'class': 'name'}).text for x in ul[0].find_all('li')]\n",
    "        teams = pd.DataFrame({'season': season, 'team': team})\n",
    "        \n",
    "        return teams\n",
    "\n",
    "    else:\n",
    "        \n",
    "        print(rider_name, 'No Teams scraped')\n",
    "\n",
    "def save_data(rider_name, teams):\n",
    "        \n",
    "    # check if rider already has teams data\n",
    "    if not os.path.isdir(os.path.join(TEAMS_PATH, rider_name)):\n",
    "        os.mkdir(os.path.join(TEAMS_PATH, rider_name))\n",
    "        \n",
    "    # save teams data\n",
    "    teams.to_csv(os.path.join(TEAMS_PATH, rider_name, 'teams.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rider_names = list(pd.read_csv(os.path.join(BASE_PATH, 'rider_names.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 8/90 [00:08<01:31,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jonas-vingegaard No Teams scraped\n",
      "jonas-vingegaard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 17/90 [00:17<01:10,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frølich-honoré-mikkel No Teams scraped\n",
      "frølich-honoré-mikkel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 29/90 [00:31<00:57,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexey-lutsenko No Teams scraped\n",
      "alexey-lutsenko\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 30/90 [00:31<00:51,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ben-o'connor No Teams scraped\n",
      "ben-o'connor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 50/90 [00:59<00:37,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "michael-valgren No Teams scraped\n",
      "michael-valgren\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 65/90 [01:17<00:22,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biniam-girmay-hailu No Teams scraped\n",
      "biniam-girmay-hailu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 81/90 [01:32<00:08,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ángel-lópez-miguel No Teams scraped\n",
      "ángel-lópez-miguel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 82/90 [01:32<00:06,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esteban-chaves No Teams scraped\n",
      "esteban-chaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 83/90 [01:33<00:05,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "michał-kwiatkowski No Teams scraped\n",
      "michał-kwiatkowski\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 88/90 [01:37<00:01,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jesús-herrada No Teams scraped\n",
      "jesús-herrada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [01:39<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "christian-eiking-odd No Teams scraped\n",
      "christian-eiking-odd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for rider_name in tqdm.tqdm(rider_names[10:100]):\n",
    "    \n",
    "    try:\n",
    "        teams = get_rider_teams(rider_name)\n",
    "        save_data(rider_name, teams)\n",
    "    except:\n",
    "        print(rider_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RIDER NAMES NOT CORRECT ON URL FOR FAILURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get race calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_calendar(years):\n",
    "\n",
    "    calendar = []\n",
    "\n",
    "    for year in years:\n",
    "\n",
    "        try:\n",
    "            url = f'https://www.procyclingstats.com/races.php?year={year}&circuit=&class=&filter=Filter'\n",
    "            res = requests.get(url)\n",
    "\n",
    "            tables = pd.read_html(res.content)\n",
    "            calendar.append(tables[0].dropna())\n",
    "\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    df_calendar = [(year, cal) for year, cal in zip(years, calendar) if not cal.empty]\n",
    "    \n",
    "    return df_calendar\n",
    "\n",
    "def save_data(calendar):\n",
    "        \n",
    "    if not os.path.isdir(CALENDARS_PATH):\n",
    "        os.mkdir(CALENDARS_PATH)\n",
    "        \n",
    "    # save calendar data\n",
    "    calendar[1].to_csv(os.path.join(CALENDARS_PATH, f'{calendar[0]}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = ['2021', '2020']\n",
    "calendar = get_race_calendar(years)\n",
    "[save_data(cal) for cal in calendar]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Race startlist + results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_racename_to_url(racename):\n",
    "    \n",
    "    race_url = racename.values[0].lower().replace(\"'\", \"-\").replace(\" \", \"-\")\n",
    "    \n",
    "    return race_url\n",
    "    \n",
    "def get_race_results(race_url, year):\n",
    "    \n",
    "    url = f'https://www.procyclingstats.com/race/{race_url}/{year}'\n",
    "    res = requests.get(url)\n",
    "\n",
    "    tables = pd.read_html(res.content)\n",
    "    last_stage = tables[0]\n",
    "    gc = tables[1]\n",
    "    points = tables[2]\n",
    "    kom = tables[3]\n",
    "    youth = tables[4]\n",
    "    teams = tables[5]\n",
    "    \n",
    "    # ALSO NEED individual stages, kom, points, youth, teams final + stage results\n",
    "    \n",
    "    return last_stage, gc, points, kom, youth, teams\n",
    "\n",
    "def get_startlist(race_url, year):\n",
    "    \n",
    "    url = f'https://www.procyclingstats.com/race/{race_url}/{year}/gc/startlist/alphabetical-with-filters'\n",
    "    res = requests.get(url)\n",
    "    \n",
    "    startlist = pd.read_html(res.content)[0].drop(['Unnamed: 3'], axis=1)\n",
    "    \n",
    "    return startlist\n",
    "\n",
    "def save_data(startlist, PATH, race_url, year):\n",
    "        \n",
    "    if not os.path.isdir(os.path.join(PATH, race_url, year)):\n",
    "        os.makedirs(os.path.join(PATH, race_url, year))\n",
    "        \n",
    "    # save data\n",
    "    startlist.to_csv(os.path.join(PATH, race_url, year, 'startlist.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2021'\n",
    "target_race = \"Giro d'Italia\"\n",
    "\n",
    "calendar = pd.read_csv(os.path.join(CALENDARS_PATH, f'{year}.csv'))\n",
    "race_url = convert_racename_to_url(calendar[calendar['Race'].str.contains(target_race)].Race)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get startlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startlist = get_startlist(race_url, year)\n",
    "save_data(startlist, STARTLISTS_PATH, race_url, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get race results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(results, PATH, race_url, year):\n",
    "        \n",
    "    if not os.path.isdir(os.path.join(PATH, race_url, year)):\n",
    "        os.makedirs(os.path.join(PATH, race_url, year))\n",
    "        \n",
    "    # save data\n",
    "    [res.to_csv(os.path.join(PATH, race_url, year, f'{name}.csv'), index=False) for res, name in zip(results, ['last_stage', 'gc', 'points', 'kom', 'youth', 'team'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_race_results(race_url, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(results, RACERESULTS_PATH, race_url, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
